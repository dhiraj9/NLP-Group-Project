{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y9iZ3b5Y97qs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GvO0K-gV-EK5"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('p3_train.csv')\n",
        "test = pd.read_csv('p3_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KHvq_AqrLBB6"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train['text'], train['label'], test_size=0.2, random_state=42)\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uQnEyKThLGMp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, Embedding, LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, GlobalMaxPooling1D, Attention\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0njm_foSkDF",
        "outputId": "86c72f30-3963-4672-ca0e-d134f53e8c3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "W6XaDDxvSmmp"
      },
      "outputs": [],
      "source": [
        "X_train_tagged_texts = []\n",
        "for text in X_train:\n",
        "    tokens = word_tokenize(text)\n",
        "    tags = pos_tag(tokens)\n",
        "    X_train_tagged_texts.append(tags)\n",
        "X_test_tagged_texts = []\n",
        "for text in X_test:\n",
        "    tokens = word_tokenize(text)\n",
        "    tags = pos_tag(tokens)\n",
        "    X_test_tagged_texts.append(tags)\n",
        "# Map POS tags to integers using NLTK's tagset\n",
        "tagset = {\"CC\": 1, \"CD\": 2, \"DT\": 3, \"EX\": 4, \"FW\": 5, \"IN\": 6, \"JJ\": 7, \"JJR\": 8, \"JJS\": 9, \"LS\": 10, \"MD\": 11,\n",
        "          \"NN\": 12, \"NNS\": 13, \"NNP\": 14, \"NNPS\": 15, \"PDT\": 16, \"POS\": 17, \"PRP\": 18, \"PRP$\": 19, \"RB\": 20,\n",
        "          \"RBR\": 21, \"RBS\": 22, \"RP\": 23, \"SYM\": 24, \"TO\": 25, \"UH\": 26, \"VB\": 27, \"VBD\": 28, \"VBG\": 29,\n",
        "          \"VBN\": 30, \"VBP\": 31, \"VBZ\": 32, \"WDT\": 33, \"WP\": 34, \"WP$\": 35, \"WRB\": 36}\n",
        "X_train_tagged = []\n",
        "for tagged_text in X_train_tagged_texts:\n",
        "    tagged_text_int = []\n",
        "    for word, tag in tagged_text:\n",
        "        if tag in tagset:\n",
        "            tagged_text_int.append(tagset[tag])\n",
        "    X_train_tagged.append(tagged_text_int)\n",
        "\n",
        "X_test_tagged = []\n",
        "for tagged_text in X_test_tagged_texts:\n",
        "    tagged_text_int = []\n",
        "    for word, tag in tagged_text:\n",
        "        if tag in tagset:\n",
        "            tagged_text_int.append(tagset[tag])\n",
        "    X_test_tagged.append(tagged_text_int)\n",
        "\n",
        "\n",
        "max_length = max([len(seq) for seq in X_train_tagged])\n",
        "max_length = max([len(seq) for seq in X_test_tagged])\n",
        "# Pad sequences to a fixed length\n",
        "# max_length = 12270\n",
        "X_train_padded = pad_sequences(X_train_tagged, maxlen=max_length, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_tagged, maxlen=max_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmbufZ0bSotp",
        "outputId": "334bfb4e-fc19-41f2-c850-8090b48ffc79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "238/238 [==============================] - 38s 129ms/step - loss: 1.7176 - accuracy: 0.3674\n",
            "Epoch 2/15\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 1.2374 - accuracy: 0.5358\n",
            "Epoch 3/15\n",
            "238/238 [==============================] - 30s 125ms/step - loss: 1.1327 - accuracy: 0.5669\n",
            "Epoch 4/15\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 1.0520 - accuracy: 0.5924\n",
            "Epoch 5/15\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.9933 - accuracy: 0.6090\n",
            "Epoch 6/15\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.9490 - accuracy: 0.6303\n",
            "Epoch 7/15\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.9330 - accuracy: 0.6328\n",
            "Epoch 8/15\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.8935 - accuracy: 0.6509\n",
            "Epoch 9/15\n",
            "238/238 [==============================] - 30s 125ms/step - loss: 0.8550 - accuracy: 0.6672\n",
            "Epoch 10/15\n",
            "238/238 [==============================] - 30s 125ms/step - loss: 0.8310 - accuracy: 0.6726\n",
            "Epoch 11/15\n",
            "238/238 [==============================] - 30s 125ms/step - loss: 0.7885 - accuracy: 0.6927\n",
            "Epoch 12/15\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.7799 - accuracy: 0.6952\n",
            "Epoch 13/15\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.7468 - accuracy: 0.7041\n",
            "Epoch 14/15\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.7191 - accuracy: 0.7244\n",
            "Epoch 15/15\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.7013 - accuracy: 0.7268\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ea0410d90>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tagset)+1, output_dim=300, input_length=max_length))\n",
        "model.add(Conv1D(64, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3))\n",
        "model.add(Conv1D(32, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPooling1D(pool_size=3))\n",
        "model.add(Dense(32, activation='tanh'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(11, activation='softmax'))  # 2 classes: generated by same method or not\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# early_stop = EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
        "# train the model\n",
        "model.fit(X_train_padded, y_train, epochs=15, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpI6pNjsLesP",
        "outputId": "5256cb10-d196-4903-b9b2-b704c1f50206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60/60 [==============================] - 4s 49ms/step - loss: 0.9413 - accuracy: 0.6481\n"
          ]
        }
      ],
      "source": [
        "# tokenizer.fit_on_texts(X_test)\n",
        "loss, acc = model.evaluate(X_test_padded, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tJsqgGkyHBR",
        "outputId": "5d99c327-c9ec-4992-ad2b-07c74ade9240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60/60 [==============================] - 4s 48ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(X_test_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiCZuWd8SvKL",
        "outputId": "a5e07094-dcfa-47f2-f762-61cfdf41e8d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3.4885248e-04, 9.9589074e-01, 1.2182490e-03, 4.3332661e-04,\n",
              "       9.9432045e-06, 5.4924272e-04, 1.8623366e-04, 7.4970976e-06,\n",
              "       1.2664089e-03, 5.3656426e-05, 3.5821951e-05], dtype=float32)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "vNHdW2LESw24"
      },
      "outputs": [],
      "source": [
        "preds_new = np.argmax(preds, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "I3OUsphqSyun"
      },
      "outputs": [],
      "source": [
        "preds_new = np.array(preds_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inmzgWOS0cQ",
        "outputId": "23912225-afbc-4ab0-8de2-a238f0a7555f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_new[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPTFf6v_S3cb",
        "outputId": "0fe52904-8ea7-4020-c6e8-4ec28f993555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 score =  0.6493691022822049\n",
            "Precision =  0.6675646685491493\n",
            "Recall =  0.6488862444507566\n",
            "Accuracy =  0.6480505795574288\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score,precision_score, recall_score, accuracy_score\n",
        "f1 = f1_score(y_test, preds_new, average='macro')\n",
        "print(\"F1 score = \",f1)\n",
        "precision = precision_score(y_test, preds_new, average='macro')\n",
        "recall = recall_score(y_test, preds_new, average='macro')\n",
        "print(\"Precision = \", precision)\n",
        "print(\"Recall = \", recall)\n",
        "print(\"Accuracy = \", accuracy_score(y_test, preds_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eCRDZw1VZ-1",
        "outputId": "3cfd6a9f-9ba4-4696-b077-43fd071ed9e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8077    0.7590    0.7826       166\n",
            "           1     0.9294    0.8827    0.9054       179\n",
            "           2     0.5732    0.5434    0.5579       173\n",
            "\n",
            "   micro avg     0.7714    0.7297    0.7500       518\n",
            "   macro avg     0.7701    0.7284    0.7486       518\n",
            "weighted avg     0.7714    0.7297    0.7500       518\n",
            "\n",
            "confusion matrix:  [0.99212598 0.96932515 0.97916667]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, roc_curve, auc, f1_score, accuracy_score, confusion_matrix\n",
        "matrix = confusion_matrix(y_test, preds_new, labels = [0, 1, 2])\n",
        "mat = matrix.diagonal()/matrix.sum(axis=1)\n",
        "print(classification_report(y_test, preds_new, labels = [0, 1, 2],digits=4))\n",
        "print('confusion matrix: ', mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MalS_BsEf9JI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
