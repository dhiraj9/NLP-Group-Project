{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a48de16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from yellowbrick.classifier import ClassPredictionError\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, f1_score, accuracy_score, confusion_matrix, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a759fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alway taught peopl like jordan peterson matt w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>don’t actual know qanon hundr leagu past stand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f becom concern cousin’ f well relationship cl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marri narcissist man littl decad final let go ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f brotherinlaw alway total jackass marri siste...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>cmv uswestern media larg neglect long histori ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>agre support idea uk elect head state current ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>disagre unit state democrat nation defin const...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>disagre clear cut side line drawn sand seen pa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>cmv crimea remain part ukrain</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     alway taught peopl like jordan peterson matt w...      0\n",
       "1     don’t actual know qanon hundr leagu past stand...      0\n",
       "2     f becom concern cousin’ f well relationship cl...      0\n",
       "3     marri narcissist man littl decad final let go ...      0\n",
       "4     f brotherinlaw alway total jackass marri siste...      0\n",
       "...                                                 ...    ...\n",
       "1506  cmv uswestern media larg neglect long histori ...      2\n",
       "1507  agre support idea uk elect head state current ...      2\n",
       "1508  disagre unit state democrat nation defin const...      2\n",
       "1509  disagre clear cut side line drawn sand seen pa...      2\n",
       "1510                      cmv crimea remain part ukrain      2\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('p3_reddit.csv')[['text', 'label']]\n",
    "print(df.shape)\n",
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f220c6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'human' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241m0\u001b[39m\u001b[38;5;241m-\u001b[39m  \u001b[43mhuman\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'human' is not defined"
     ]
    }
   ],
   "source": [
    "0 -  human\n",
    "1 - gpt3\n",
    "2 - instruct_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb07669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac8902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281ee49",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e3dd275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1194,) (299,) (1194,) (299,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'],\n",
    "                                                    df['label'],\n",
    "                                                    stratify = df['label'],\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 1234)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3615ae2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    401\n",
       "2    400\n",
       "0    393\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f13b8c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1194, 9541) (299, 9541) (1194,) (299,)\n"
     ]
    }
   ],
   "source": [
    "v = TfidfVectorizer()\n",
    "\n",
    "X_train = v.fit_transform(X_train)\n",
    "X_test = v.transform(X_test)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "276aa507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1194x9541 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 86095 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89d623",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab12587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ctrl', 'gpt', 'gpt2', 'grover', 'xlm', 'xlnet', 'pplm', 'human', 'fair', 'gpt3', 'instruct_gpt']\n",
    "    \n",
    "def visualizer(clf):\n",
    "    visualizer = ClassPredictionError(clf, classes= labels)\n",
    "\n",
    "    # Fit the training data to the visualizer\n",
    "    visualizer.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    visualizer.score(X_test, y_test)\n",
    "\n",
    "    # Draw visualization\n",
    "    visualizer.show()\n",
    "    \n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "\n",
    "def get_confusion_matrix(model):\n",
    "   \n",
    "    cm = ConfusionMatrix(\n",
    "        model, classes=labels,\n",
    "        percent=True\n",
    "        #label_encoder={0: 'Adelie', 1: 'Chinstrap', 2: 'Gentoo'}\n",
    "    )\n",
    "    cm.fit(X_train, y_train)\n",
    "    cm.score(X_test, y_test)\n",
    "    cm.show();\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "    \n",
    "def metrics(pred):\n",
    "    matrix = confusion_matrix(y_test, pred, labels = labels)\n",
    "    mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    print(classification_report(y_test, pred, labels = labels,\n",
    "                                digits=4))\n",
    "\n",
    "    print('confusion matrix: ', mat)\n",
    "\n",
    "    Accuracy = accuracy_score(y_test,pred)\n",
    "    F1 = f1_score(y_test, pred, average='macro')\n",
    "    print(\"Accuracy:\", Accuracy)\n",
    "\n",
    "    rec = recall_score(y_test, pred, average='macro')\n",
    "    print('Recall: ', rec)\n",
    "    prec = precision_score(y_test, pred, average='macro')\n",
    "    print('Precision: ', prec)\n",
    "\n",
    "    print('F1:', F1)\n",
    "    \n",
    "def get_predictions(tpr, fpr, threshold, ypred):\n",
    "    #If tpr is hight & fpr is low : (tpr*(1-fpr)) is maximum\n",
    "    actual_ypred = []\n",
    "\n",
    "    thres = threshold[np.argmax(tpr * (1 - fpr))]\n",
    "    for value in ypred:\n",
    "        if value < thres:\n",
    "            actual_ypred.append(0)\n",
    "        else:\n",
    "            actual_ypred.append(1)\n",
    "    return actual_ypred\n",
    "    \n",
    "# def get_roc_curve(model_name, classifier):\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "def plot_ROC_curve(model):\n",
    "    # Creating visualization with the readable labels\n",
    "    visualizer = ROCAUC(model, classes = labels)\n",
    "                                        \n",
    "    # Fitting to the training data first then scoring with the test data                                    \n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    visualizer.show()\n",
    "    \n",
    "    return visualizer\n",
    "\n",
    "\n",
    "def get_confusion_matrix(model_name, roc_results):\n",
    "    actual_ypred_train = get_predictions(roc_results['tpr_train'],\n",
    "                                         roc_results['fpr_train'],\n",
    "                                         roc_results['threshold_train'],\n",
    "                                         roc_results['ypred_train'])\n",
    "\n",
    "    matrix_train = confusion_matrix(y_train, actual_ypred_train)\n",
    "\n",
    "    actual_ypred_test = get_predictions(roc_results['tpr_test'],\n",
    "                                        roc_results['fpr_test'],\n",
    "                                        roc_results['threshold_test'],\n",
    "                                        roc_results['ypred_test'])\n",
    "\n",
    "    matrix_test = confusion_matrix(y_test, actual_ypred_test)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = [12, 5]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    f, axes = plt.subplots(1, 2)\n",
    "    \n",
    "    axes[0].title.set_text(f'{model_name} Training Confusion Matrix')\n",
    "    sns.heatmap(matrix_train, annot = True, ax = axes[0], fmt = \"d\")\n",
    "\n",
    "\n",
    "    sns.heatmap(matrix_test, annot = True, ax = axes[1], fmt = \"d\")\n",
    "    axes[1].title.set_text(f'{model_name} Testing Confusion Matrix')\n",
    "\n",
    "    return actual_ypred_test, actual_ypred_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e75da7",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "248a6d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params  {'max_depth': 10, 'max_samples': 0.6, 'n_estimators': 90}\n"
     ]
    }
   ],
   "source": [
    "randomforest_model = RandomForestClassifier()\n",
    "\n",
    "parameters = { 'max_depth' : [10, 20, 30],\n",
    "               'n_estimators' : [90, 150, 180],\n",
    "               'max_samples' : [0.6, 0.8]\n",
    " }\n",
    "\n",
    "cross_validation = 3\n",
    "scoring_metric = \"f1\"\n",
    "randomforest_model_cv = GridSearchCV(randomforest_model, \n",
    "                                     parameters,\n",
    "                                     cv = cross_validation,\n",
    "                                     scoring = scoring_metric,\n",
    "                                     return_train_score=True)\n",
    "\n",
    "randomforest_model_cv.fit(X_train, y_train)\n",
    "print('Best Params ', randomforest_model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f410f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "     'max_depth' : 10,\n",
    "     'n_estimators' : 90,\n",
    "     'max_samples' : 0.6\n",
    "}\n",
    "randomforest_model = RandomForestClassifier(max_depth = parameters['max_depth'],\n",
    "                                            max_samples = parameters['max_samples'],\n",
    "                                            n_estimators = parameters['n_estimators'])\n",
    "\n",
    "randomforest_model.fit(X_train, y_train)\n",
    "pred = randomforest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19731a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9082    0.9519        98\n",
      "           1     0.6899    0.8812    0.7739       101\n",
      "           2     0.8272    0.6700    0.7403       100\n",
      "\n",
      "    accuracy                         0.8194       299\n",
      "   macro avg     0.8390    0.8198    0.8220       299\n",
      "weighted avg     0.8375    0.8194    0.8210       299\n",
      "\n",
      "confusion matrix:  [0.90816327 0.88118812 0.67      ]\n",
      "Accuracy: 0.8193979933110368\n",
      "Recall:  0.8197837947060012\n",
      "Precision:  0.8390276581491052\n",
      "F1: 0.8220387309816596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc, f1_score, accuracy_score, confusion_matrix\n",
    "matrix = confusion_matrix(y_test, pred, labels = [0,1,2])\n",
    "mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "print(classification_report(y_test, pred, labels = [0,1,2],\n",
    "                            digits=4))\n",
    "print('confusion matrix: ', mat)\n",
    "\n",
    "Accuracy = accuracy_score(y_test,pred)\n",
    "F1 = f1_score(y_test, pred, average='macro')\n",
    "print(\"Accuracy:\", Accuracy)\n",
    "\n",
    "rec = recall_score(y_test, pred, average='macro')\n",
    "print('Recall: ', rec)\n",
    "prec = precision_score(y_test, pred, average='macro')\n",
    "print('Precision: ', prec)\n",
    "\n",
    "print('F1:', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c9638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5a5dfe6",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c360bfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params  {'C': 0.01, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "parameters = { 'C' : [0.01, 0.1, 1, 3, 10],\n",
    "               'penalty' : ['l2', 'elasticnet']\n",
    "             }\n",
    "\n",
    "cross_validation = 3\n",
    "scoring_metric = \"f1\"\n",
    "\n",
    "logistic_model_cv = GridSearchCV(logistic_model,\n",
    "                                 parameters,\n",
    "                                 cv = cross_validation,\n",
    "                                 scoring = scoring_metric,\n",
    "                                 return_train_score=True)\n",
    "\n",
    "logistic_model_cv.fit(X_train, y_train)\n",
    "print('Best Params ', logistic_model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "502fc652",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'C' : 1,\n",
    "               'penalty' : 'l2'\n",
    " }\n",
    "\n",
    "logistic_model = LogisticRegression(C = parameters['C'], penalty = parameters['penalty'])\n",
    "logistic_model.fit(X_train, y_train)\n",
    "pred = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caa2a9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9368    0.9082    0.9223        98\n",
      "           1     0.7374    0.7228    0.7300       101\n",
      "           2     0.7429    0.7800    0.7610       100\n",
      "\n",
      "    accuracy                         0.8027       299\n",
      "   macro avg     0.8057    0.8036    0.8044       299\n",
      "weighted avg     0.8046    0.8027    0.8034       299\n",
      "\n",
      "confusion matrix:  [0.90816327 0.72277228 0.78      ]\n",
      "Accuracy: 0.802675585284281\n",
      "Recall:  0.8036451808446151\n",
      "Precision:  0.8056909951646793\n",
      "F1: 0.8044184675007373\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, pred, labels = [0,1,2])\n",
    "mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "print(classification_report(y_test, pred, labels = [0,1,2],\n",
    "                            digits=4))\n",
    "print('confusion matrix: ', mat)\n",
    "\n",
    "Accuracy = accuracy_score(y_test,pred)\n",
    "F1 = f1_score(y_test, pred, average='macro')\n",
    "print(\"Accuracy:\", Accuracy)\n",
    "\n",
    "rec = recall_score(y_test, pred, average='macro')\n",
    "print('Recall: ', rec)\n",
    "prec = precision_score(y_test, pred, average='macro')\n",
    "print('Precision: ', prec)\n",
    "\n",
    "print('F1:', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca298d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c982021",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a9361d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params  {'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 90}\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "xgboost_model = xgboost.XGBClassifier()\n",
    "\n",
    "parameters = { 'max_depth' : [10, 20, 30],\n",
    "               'n_estimators' : [90, 150, 180],\n",
    "               'min_child_weight' : [1, 5, 10 ]\n",
    " }\n",
    "\n",
    "cross_validation = 3\n",
    "scoring_metric = \"f1\"\n",
    "xgboost_model_cv = GridSearchCV(xgboost_model, \n",
    "                                parameters,\n",
    "                                cv = cross_validation,\n",
    "                                scoring = scoring_metric,\n",
    "                                return_train_score=True)\n",
    "\n",
    "xgboost_model_cv.fit(X_train, y_train)\n",
    "print('Best Params ', xgboost_model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d52631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'max_depth' : 10,\n",
    "               'min_child_weight' : 1,\n",
    "               'n_estimators' : 150\n",
    " }\n",
    "\n",
    "xgboost_model = xgboost.XGBClassifier(max_depth = parameters['max_depth'],\n",
    "                                      min_child_weight = parameters['min_child_weight'],\n",
    "                                      n_estimators = parameters['n_estimators'])\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "pred = xgboost_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "511019da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9394    0.9490    0.9442        98\n",
      "           1     0.7434    0.8317    0.7850       101\n",
      "           2     0.8276    0.7200    0.7701       100\n",
      "\n",
      "    accuracy                         0.8328       299\n",
      "   macro avg     0.8368    0.8336    0.8331       299\n",
      "weighted avg     0.8358    0.8328    0.8322       299\n",
      "\n",
      "confusion matrix:  [0.94897959 0.83168317 0.72      ]\n",
      "Accuracy: 0.8327759197324415\n",
      "Recall:  0.833554253384522\n",
      "Precision:  0.8367809927162995\n",
      "F1: 0.833087547152005\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, pred, labels = [0,1,2])\n",
    "mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "print(classification_report(y_test, pred, labels = [0,1,2],\n",
    "                            digits=4))\n",
    "print('confusion matrix: ', mat)\n",
    "\n",
    "Accuracy = accuracy_score(y_test,pred)\n",
    "F1 = f1_score(y_test, pred, average='macro')\n",
    "print(\"Accuracy:\", Accuracy)\n",
    "\n",
    "rec = recall_score(y_test, pred, average='macro')\n",
    "print('Recall: ', rec)\n",
    "prec = precision_score(y_test, pred, average='macro')\n",
    "print('Precision: ', prec)\n",
    "\n",
    "print('F1:', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413992f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "700c80f7",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dc9a66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params  {'kernel': 'poly', 'max_iter': 20}\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC()\n",
    "\n",
    "parameters = { 'kernel' : ['poly', 'rbf', 'sigmoid'],\n",
    "               'max_iter' : [20, 50, 100]\n",
    " }\n",
    "\n",
    "cross_validation = 3\n",
    "scoring_metric = \"f1\"\n",
    "svm_model_cv = GridSearchCV(svm_model, \n",
    "                            parameters,\n",
    "                            cv = cross_validation,\n",
    "                            scoring = scoring_metric,\n",
    "                            return_train_score=True)\n",
    "\n",
    "svm_model_cv.fit(X_train, y_train)\n",
    "print('Best Params ', svm_model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc7048ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "         'kernel' : 'poly',\n",
    "         'max_iter' : 20,\n",
    "        }\n",
    "\n",
    "svm_model = SVC(kernel = parameters['kernel'],\n",
    "max_iter = parameters['max_iter'], probability = True)\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f77a614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8889    0.2449    0.3840        98\n",
      "           1     0.3483    0.9208    0.5054       101\n",
      "           2     0.0000    0.0000    0.0000       100\n",
      "\n",
      "    accuracy                         0.3913       299\n",
      "   macro avg     0.4124    0.3886    0.2965       299\n",
      "weighted avg     0.4090    0.3913    0.2966       299\n",
      "\n",
      "confusion matrix:  [0.24489796 0.92079208 0.        ]\n",
      "Accuracy: 0.391304347826087\n",
      "Recall:  0.3885633461305314\n",
      "Precision:  0.41240116521015396\n",
      "F1: 0.29647826086956525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc, f1_score, accuracy_score, confusion_matrix\n",
    "matrix = confusion_matrix(y_test, pred, labels = [0,1,2])\n",
    "mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "print(classification_report(y_test, pred, labels = [0,1,2],\n",
    "                            digits=4))\n",
    "print('confusion matrix: ', mat)\n",
    "\n",
    "Accuracy = accuracy_score(y_test,pred)\n",
    "F1 = f1_score(y_test, pred, average='macro')\n",
    "print(\"Accuracy:\", Accuracy)\n",
    "\n",
    "rec = recall_score(y_test, pred, average='macro')\n",
    "print('Recall: ', rec)\n",
    "prec = precision_score(y_test, pred, average='macro')\n",
    "print('Precision: ', prec)\n",
    "\n",
    "print('F1:', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23052e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9372ea7",
   "metadata": {},
   "source": [
    "### Binomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5a8aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_model = BernoulliNB()\n",
    "bnb_model.fit(X_train, y_train)\n",
    "pred = bnb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54ef8991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8265    0.9050        98\n",
      "           1     0.7179    0.8317    0.7706       101\n",
      "           2     0.7228    0.7300    0.7264       100\n",
      "\n",
      "    accuracy                         0.7960       299\n",
      "   macro avg     0.8136    0.7961    0.8007       299\n",
      "weighted avg     0.8120    0.7960    0.7999       299\n",
      "\n",
      "confusion matrix:  [0.82653061 0.83168317 0.73      ]\n",
      "Accuracy: 0.7959866220735786\n",
      "Recall:  0.7960712601872432\n",
      "Precision:  0.8135736650588136\n",
      "F1: 0.8006794313332454\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, pred, labels = [0,1,2])\n",
    "mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "print(classification_report(y_test, pred, labels = [0,1,2],\n",
    "                            digits=4))\n",
    "print('confusion matrix: ', mat)\n",
    "\n",
    "Accuracy = accuracy_score(y_test,pred)\n",
    "F1 = f1_score(y_test, pred, average='macro')\n",
    "print(\"Accuracy:\", Accuracy)\n",
    "\n",
    "rec = recall_score(y_test, pred, average='macro')\n",
    "print('Recall: ', rec)\n",
    "prec = precision_score(y_test, pred, average='macro')\n",
    "print('Precision: ', prec)\n",
    "\n",
    "print('F1:', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae5e9666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Task P3 : TF vectors\n",
      "╒══════════════════════════╤══════════╤═══════════╤════════╤══════════╤═══════════╤══════════╕\n",
      "│ Model                    │ Accuracy │ Precision │ Recall │ F1 Score │ Train AUC │ Test AUC │\n",
      "├──────────────────────────┼──────────┼───────────┼────────┼──────────┼───────────┼──────────┤\n",
      "│ Logistic Regression      │ 80.2     │ 80.4      │ 80.3   │ 80.4     │           │          │\n",
      "├──────────────────────────┼──────────┼───────────┼────────┼──────────┼───────────┼──────────┤\n",
      "│ XGBoost Classifier       │ 83.2     │ 83.6      │ 83.3   │ 83.3     │           │          │\n",
      "├──────────────────────────┼──────────┼───────────┼────────┼──────────┼───────────┼──────────┤\n",
      "│ Random Forest Classifier │ 81.9     │ 83.9      │ 81.9   │ 82.2     │           │          │\n",
      "├──────────────────────────┼──────────┼───────────┼────────┼──────────┼───────────┼──────────┤\n",
      "│ SVM Classifier           │ 39.1     │ 41.2      │ 38.8   │ 30.7     │           │          │\n",
      "├──────────────────────────┼──────────┼───────────┼────────┼──────────┼───────────┼──────────┤\n",
      "│ Naive Bayes Classifier   │ 79.5     │ 81.3      │ 79.6   │ 80.0     │           │          │\n",
      "╘══════════════════════════╧══════════╧═══════════╧════════╧══════════╧═══════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "import tabulate\n",
    "print('Reddit Task P3 : TF vectors')\n",
    "conclusion = [['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Train AUC', 'Test AUC', ],\n",
    "              ['Logistic Regression', 80.2, 80.4, 80.3, 80.4],\n",
    "              ['XGBoost Classifier', 83.2, 83.6, 83.3, 83.3],\n",
    "              ['Random Forest Classifier', 81.9, 83.9, 81.9, 82.2],\n",
    "              ['SVM Classifier', 39.1, 41.2, 38.8, 30.7],\n",
    "              ['Naive Bayes Classifier',  79.5, 81.3, 79.6, 80.0],   \n",
    "             ]\n",
    "print(tabulate.tabulate(conclusion, tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932072d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
